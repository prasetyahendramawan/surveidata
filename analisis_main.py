import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.stats import pearsonr, spearmanr, chi2_contingency, normaltest
import nltk
from nltk.corpus import stopwords
import string
from collections import Counter
from io import BytesIO
from reportlab.lib.pagesizes import A4
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image, Table
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.lib.utils import ImageReader
from datetime import datetime
import math
import warnings
warnings.filterwarnings("ignore")

# --------------------------
# TEXTS: EN, ID, CN, JP, KR
# --------------------------
TEXTS = {
    "EN": {
        "title": "Survey Data Analyzer",
        "subtitle": "Upload, explore, analyze survey data and export a PDF report",
        "upload": "Upload CSV / XLS / XLSX",
        "preview": "Data preview (max 1000 rows)",
        "summary": "Dataset summary",
        "rows": "Rows",
        "cols": "Columns",
        "num_cols": "Numeric columns",
        "cat_cols": "Categorical columns",
        "text_cols": "Text columns",
        "descriptive_tab": "Descriptive Stats",
        "visual_tab": "Visualizations",
        "corr_tab": "Correlations & Tests",
        "text_tab": "Text Processing",
        "select_numeric": "Select numeric column",
        "stats_title": "Descriptive statistics",
        "normality_title": "Normality test (D'Agostino & Pearson)",
        "statistic": "Statistic",
        "p_value": "p-value",
        "interpretation": "Interpretation",
        "histogram": "Histogram",
        "boxplot": "Boxplot",
        "frequency_table": "Frequency table (count + percent)",
        "select_x": "Select X (numeric)",
        "select_y": "Select Y (numeric)",
        "scatter_title": "Scatter plot",
        "bar_chart": "Bar chart (top 20)",
        "select_categorical": "Select categorical column",
        "pearson": "Pearson correlation",
        "spearman": "Spearman correlation",
        "chi_square": "Chi-square test",
        "observed": "Observed",
        "expected": "Expected",
        "corr_matrix": "Pearson correlation matrix",
        "spearman_matrix": "Spearman correlation matrix",
        "detect_text": "Detected text columns",
        "preprocess": "Preprocess text (lowercase, remove punctuation, tokenize, remove stopwords)",
        "sample_tokens": "Sample tokens",
        "top_words": "Top 10 words",
        "generate_pdf": "Generate PDF Report",
        "download_pdf": "Download PDF",
        "dark_mode": "Dark Mode",
        "language": "Language",
        "no_data": "No data loaded. Please upload a file.",
        "insufficient": "Insufficient data for this operation",
        "pdf_generating": "Building PDF ‚Äî this may take a moment...",
        "pdf_done": "PDF generated",
        "pdf_name": "survey_report",
        "select_two_numeric": "Select two numeric columns",
        "select_two_categorical": "Select two categorical columns",
        "select_text_column": "Select text column",
        "normal": "Normal",
        "not_normal": "Not normal",
        "categorical_frequency": "Categorical frequency (top 10)",
        "error_processing_text": "Error processing text",
        "need_two_numeric_scatter": "Need at least two numeric columns for scatter",
        "no_categorical_bar": "No categorical columns for bar chart",
        "need_two_numeric_corr": "Need at least two numeric columns for correlations",
        "need_two_categorical_chi": "Need at least two categorical columns for chi-square",
        "no_text_columns": "No text columns found",
        "processing_text": "Text Processing",
        "select_second_numeric": "Select second numeric",
        "select_second_categorical": "Select second categorical",
        "remove_stopwords": "Remove English stopwords (NLTK)",
        "interpretation_pearson": "Interpretation (Pearson):",
        "interpretation_spearman": "Interpretation (Spearman):",
        "positive": "Positive",
        "negative": "Negative",
        "no_relation": "No relation",
        "pearson_error": "Pearson: error computing",
        "spearman_error": "Spearman: error computing",
        "chi_square_error": "Chi-square error",
        "normality_error": "Normality test: error",
        "export_report": "Export / Report",
        "pdf_description": "Generate a PDF report that includes dataset metadata, numeric statistics, normality results, plots (histogram & boxplot), correlation matrix, top categorical frequencies, and top words for text columns. Limited number of items included to keep PDF manageable.",
        "interpretation_chi": "Interpretation (Chi-square):",
        "significant": "Significant association",
        "not_significant": "No significant association",
        "x_total": "X Total",
        "y_total": "Y Total"
    },
    "ID": {
        "title": "Aplikasi Analisis Data Survei",
        "subtitle": "Unggah, jelajahi, analisis data survei dan ekspor laporan PDF",
        "upload": "Unggah CSV / XLS / XLSX",
        "preview": "Pratinjau data (maks 1000 baris)",
        "summary": "Ringkasan dataset",
        "rows": "Baris",
        "cols": "Kolom",
        "num_cols": "Kolom numerik",
        "cat_cols": "Kolom kategorikal",
        "text_cols": "Kolom teks",
        "descriptive_tab": "Statistik Deskriptif",
        "visual_tab": "Visualisasi",
        "corr_tab": "Korelasi & Uji",
        "text_tab": "Pemrosesan Teks",
        "select_numeric": "Pilih kolom numerik",
        "stats_title": "Statistik deskriptif",
        "normality_title": "Uji normalitas (D'Agostino & Pearson)",
        "statistic": "Statistik",
        "p_value": "p-value",
        "interpretation": "Interpretasi",
        "histogram": "Histogram",
        "boxplot": "Boxplot",
        "frequency_table": "Tabel frekuensi (count + persen)",
        "select_x": "Pilih X (numerik)",
        "select_y": "Pilih Y (numerik)",
        "scatter_title": "Plot scatter",
        "bar_chart": "Diagram batang (top 20)",
        "select_categorical": "Pilih kolom kategorikal",
        "pearson": "Korelasi Pearson",
        "spearman": "Korelasi Spearman",
        "chi_square": "Uji Chi-square",
        "observed": "Observed",
        "expected": "Expected",
        "corr_matrix": "Matriks korelasi Pearson",
        "spearman_matrix": "Matriks korelasi Spearman",
        "detect_text": "Kolom teks terdeteksi",
        "preprocess": "Preproses teks (lowercase, hapus tanda baca, token, hapus stopwords)",
        "sample_tokens": "Contoh token",
        "top_words": "10 kata terbanyak",
        "generate_pdf": "Buat Laporan PDF",
        "download_pdf": "Unduh PDF",
        "dark_mode": "Mode Gelap",
        "language": "Bahasa",
        "no_data": "Tidak ada data. Silakan unggah file.",
        "insufficient": "Data tidak cukup untuk operasi ini",
        "pdf_generating": "Membangun PDF ‚Äî mohon tunggu...",
        "pdf_done": "PDF berhasil dibuat",
        "pdf_name": "laporan_survey",
        "no_categorical_bar": "Tidak ada kolom kategorikal untuk diagram batang",
        "need_two_numeric_corr": "Perlu setidaknya dua kolom numerik untuk korelasi",
        "need_two_categorical_chi": "Perlu setidaknya dua kolom kategorikal untuk uji chi-square",
        "no_text_columns": "Tidak ada kolom teks ditemukan",
        "remove_stopwords": "Hapus stopwords bahasa Inggris (NLTK)",
        "interpretation_pearson": "Interpretasi (Pearson):",
        "interpretation_spearman": "Interpretasi (Spearman):",
        "positive": "Positif",
        "negative": "Negatif",
        "no_relation": "Tidak ada hubungan",
        "pearson_error": "Pearson: kesalahan menghitung",
        "spearman_error": "Spearman: kesalahan menghitung",
        "chi_square_error": "Kesalahan chi-square",
        "normality_error": "Uji normalitas: kesalahan",
        "export_report": "Ekspor / Laporan",
        "pdf_description": "Buat laporan PDF yang mencakup metadata dataset, statistik numerik, hasil normalitas, plot (histogram & boxplot), matriks korelasi, frekuensi kategorikal teratas, dan kata teratas untuk kolom teks. Jumlah item terbatas untuk menjaga PDF tetap mudah dikelola.",
        "categorical_frequency": "Frekuensi kategorikal (top 10)",
        "error_processing_text": "Kesalahan memproses teks",
        "need_two_numeric_scatter": "Perlu setidaknya dua kolom numerik untuk scatter",
        "no_categorical_bar": "Tidak ada kolom kategorikal untuk diagram batang",
        "need_two_numeric_corr": "Perlu setidaknya dua kolom numerik untuk korelasi",
        "need_two_categorical_chi": "Perlu setidaknya dua kolom kategorikal untuk uji chi-square",
        "no_text_columns": "Tidak ada kolom teks ditemukan",
        "processing_text": "Pemrosesan Teks",
        "select_second_numeric": "Pilih numerik kedua",
        "select_second_categorical": "Pilih kategorikal kedua",
        "remove_stopwords": "Hapus stopwords bahasa Inggris (NLTK)",
        "interpretation_pearson": "Interpretasi (Pearson):",
        "interpretation_spearman": "Interpretasi (Spearman):",
        "positive": "Positif",
        "negative": "Negatif",
        "no_relation": "Tidak ada hubungan",
        "pearson_error": "Pearson: kesalahan menghitung",
        "spearman_error": "Spearman: kesalahan menghitung",
        "chi_square_error": "Kesalahan chi-square",
        "normality_error": "Uji normalitas: kesalahan",
        "export_report": "Ekspor / Laporan",
        "pdf_description": "Buat laporan PDF yang mencakup metadata dataset, statistik numerik, hasil normalitas, plot (histogram & boxplot), matriks korelasi, frekuensi kategorikal teratas, dan kata teratas untuk kolom teks. Jumlah item terbatas untuk menjaga PDF tetap mudah dikelola.",
        "interpretation_chi": "Interpretasi (Chi-square):",
        "significant": "Asosiasi signifikan",
        "not_significant": "Tidak ada asosiasi signifikan",
        "x_total": "Total X",
        "y_total": "Total Y",
        "select_two_numeric": "Pilih dua kolom numerik",
        "select_two_categorical": "Pilih dua kolom kategorikal",
        "select_text_column": "Pilih kolom teks",
        "normal": "Normal",
        "not_normal": "Tidak normal",
        "categorical_frequency": "Frekuensi kategorikal (top 10)"
    },
    "CN": {
        "title": "Ë∞ÉÊü•Êï∞ÊçÆÂàÜÊûêÂô®",
        "subtitle": "‰∏ä‰º†„ÄÅÊé¢Á¥¢„ÄÅÂàÜÊûêË∞ÉÊü•Êï∞ÊçÆÂπ∂ÂØºÂá∫ PDF Êä•Âëä",
        "upload": "‰∏ä‰º† CSV / XLS / XLSX",
        "preview": "Êï∞ÊçÆÈ¢ÑËßàÔºàÊúÄÂ§ö1000Ë°åÔºâ",
        "summary": "Êï∞ÊçÆÈõÜÊëòË¶Å",
        "rows": "Ë°åÊï∞",
        "cols": "ÂàóÊï∞",
        "num_cols": "Êï∞ÂÄºÂàó",
        "cat_cols": "ÂàÜÁ±ªÂàó",
        "text_cols": "ÊñáÊú¨Âàó",
        "descriptive_tab": "ÊèèËø∞ÊÄßÁªüËÆ°",
        "visual_tab": "ÂèØËßÜÂåñ",
        "corr_tab": "Áõ∏ÂÖ≥‰∏éÊ£ÄÈ™å",
        "text_tab": "ÊñáÊú¨Â§ÑÁêÜ",
        "select_numeric": "ÈÄâÊã©Êï∞ÂÄºÂàó",
        "stats_title": "ÊèèËø∞ÊÄßÁªüËÆ°",
        "normality_title": "Ê≠£ÊÄÅÊÄßÊ£ÄÈ™å (D'Agostino & Pearson)",
        "statistic": "ÁªüËÆ°Èáè",
        "p_value": "p ÂÄº",
        "interpretation": "Ëß£Èáä",
        "histogram": "Áõ¥ÊñπÂõæ",
        "boxplot": "ÁÆ±Á∫øÂõæ",
        "frequency_table": "È¢ëÁéáË°®ÔºàËÆ°Êï∞ + ÁôæÂàÜÊØîÔºâ",
        "select_x": "ÈÄâÊã© XÔºàÊï∞ÂÄºÔºâ",
        "select_y": "ÈÄâÊã© YÔºàÊï∞ÂÄºÔºâ",
        "scatter_title": "Êï£ÁÇπÂõæ",
        "bar_chart": "Êü±Áä∂ÂõæÔºàÂâç20Ôºâ",
        "select_categorical": "ÈÄâÊã©ÂàÜÁ±ªÂàó",
        "pearson": "ÁöÆÂ∞îÈÄäÁõ∏ÂÖ≥",
        "spearman": "ÊñØÁöÆÂ∞îÊõºÁõ∏ÂÖ≥",
        "chi_square": "Âç°ÊñπÊ£ÄÈ™å",
        "observed": "ËßÇÂØüÂÄº",
        "expected": "ÊúüÊúõÂÄº",
        "corr_matrix": "ÁöÆÂ∞îÈÄäÁõ∏ÂÖ≥Áü©Èòµ",
        "spearman_matrix": "ÊñØÁöÆÂ∞îÊõºÁõ∏ÂÖ≥Áü©Èòµ",
        "detect_text": "Ê£ÄÊµãÂà∞ÁöÑÊñáÊú¨Âàó",
        "preprocess": "ÊñáÊú¨È¢ÑÂ§ÑÁêÜÔºàÂ∞èÂÜô„ÄÅÂéªÊ†áÁÇπ„ÄÅÂàÜËØç„ÄÅÂéªÂÅúÁî®ËØçÔºâ",
        "sample_tokens": "Á§∫‰æãËØç",
        "top_words": "Ââç10ËØç",
        "generate_pdf": "ÁîüÊàê PDF Êä•Âëä",
        "download_pdf": "‰∏ãËΩΩ PDF",
        "dark_mode": "Ê∑±Ëâ≤Ê®°Âºè",
        "language": "ËØ≠Ë®Ä",
        "no_data": "Êú™Âä†ËΩΩÊï∞ÊçÆ„ÄÇËØ∑‰∏ä‰º†Êñá‰ª∂„ÄÇ",
        "insufficient": "Ê≠§Êìç‰ΩúÁöÑÊï∞ÊçÆ‰∏çË∂≥",
        "pdf_generating": "Ê≠£Âú®ÁîüÊàê PDFÔºåËØ∑Á®çÂÄô...",
        "pdf_done": "PDF Â∑≤ÁîüÊàê",
        "pdf_name": "Ë∞ÉÊü•Êä•Âëä"
    },
    "JP": {
        "title": "Ë™øÊüª„Éá„Éº„ÇøÂàÜÊûê„ÉÑ„Éº„É´",
        "subtitle": "„Éá„Éº„Çø„Çí„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ„Åó„Å¶Ëß£Êûê„Åó„ÄÅPDF„É¨„Éù„Éº„Éà„ÇíÂá∫Âäõ„Åó„Åæ„Åô",
        "upload": "CSV / XLS / XLSX „Çí„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ",
        "preview": "„Éá„Éº„Çø„Éó„É¨„Éì„É•„ÉºÔºàÊúÄÂ§ß1000Ë°åÔºâ",
        "summary": "„Éá„Éº„Çø„Çª„ÉÉ„ÉàÊ¶ÇË¶Å",
        "rows": "Ë°åÊï∞",
        "cols": "ÂàóÊï∞",
        "num_cols": "Êï∞ÂÄ§Âàó",
        "cat_cols": "„Ç´„ÉÜ„Ç¥„É™Âàó",
        "text_cols": "„ÉÜ„Ç≠„Çπ„ÉàÂàó",
        "descriptive_tab": "Ë®òËø∞Áµ±Ë®à",
        "visual_tab": "ÂèØË¶ñÂåñ",
        "corr_tab": "Áõ∏Èñ¢„Å®Ê§úÂÆö",
        "text_tab": "„ÉÜ„Ç≠„Çπ„ÉàÂá¶ÁêÜ",
        "select_numeric": "Êï∞ÂÄ§Âàó„ÇíÈÅ∏Êäû",
        "stats_title": "Ë®òËø∞Áµ±Ë®àÈáè",
        "normality_title": "Ê≠£Ë¶èÊÄßÊ§úÂÆö (D'Agostino & Pearson)",
        "statistic": "Áµ±Ë®àÈáè",
        "p_value": "pÂÄ§",
        "interpretation": "Ëß£Èáà",
        "histogram": "„Éí„Çπ„Éà„Ç∞„É©„É†",
        "boxplot": "ÁÆ±„Å≤„ÅíÂõ≥",
        "frequency_table": "È†ªÂ∫¶Ë°®ÔºàÂÄãÊï∞ + Ââ≤ÂêàÔºâ",
        "select_x": "X„ÇíÈÅ∏ÊäûÔºàÊï∞ÂÄ§Ôºâ",
        "select_y": "Y„ÇíÈÅ∏ÊäûÔºàÊï∞ÂÄ§Ôºâ",
        "scatter_title": "Êï£Â∏ÉÂõ≥",
        "bar_chart": "Ê£í„Ç∞„É©„ÉïÔºà‰∏ä‰Ωç20Ôºâ",
        "select_categorical": "„Ç´„ÉÜ„Ç¥„É™Âàó„ÇíÈÅ∏Êäû",
        "pearson": "„Éî„Ç¢„ÇΩ„É≥Áõ∏Èñ¢",
        "spearman": "„Çπ„Éî„Ç¢„Éû„É≥Áõ∏Èñ¢",
        "chi_square": "„Ç´„Ç§‰∫å‰πóÊ§úÂÆö",
        "observed": "Ë¶≥Ê∏¨ÂÄ§",
        "expected": "ÊúüÂæÖÂÄ§",
        "corr_matrix": "„Éî„Ç¢„ÇΩ„É≥Áõ∏Èñ¢Ë°åÂàó",
        "spearman_matrix": "„Çπ„Éî„Ç¢„Éû„É≥Áõ∏Èñ¢Ë°åÂàó",
        "detect_text": "Ê§úÂá∫„Åï„Çå„Åü„ÉÜ„Ç≠„Çπ„ÉàÂàó",
        "preprocess": "„ÉÜ„Ç≠„Çπ„ÉàÂâçÂá¶ÁêÜÔºàÂ∞èÊñáÂ≠óÂåñ„ÉªÂè•Ë™≠ÁÇπÂâäÈô§„ÉªÂàÜÂâ≤„Éª„Çπ„Éà„ÉÉ„Éó„ÉØ„Éº„ÉâÈô§ÂéªÔºâ",
        "sample_tokens": "„Éà„Éº„ÇØ„É≥‰æã",
        "top_words": "‰∏ä‰Ωç10Ë™û",
        "generate_pdf": "PDF„É¨„Éù„Éº„Éà„Çí‰ΩúÊàê",
        "download_pdf": "PDF„Çí„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ",
        "dark_mode": "„ÉÄ„Éº„ÇØ„É¢„Éº„Éâ",
        "language": "Ë®ÄË™û",
        "no_data": "„Éá„Éº„Çø„ÅåË™≠„ÅøËæº„Åæ„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇ„Éï„Ç°„Ç§„É´„Çí„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ",
        "insufficient": "„Åì„ÅÆÊìç‰Ωú„Å´„ÅØ„Éá„Éº„Çø„Åå‰∏çÂçÅÂàÜ„Åß„Åô",
        "pdf_generating": "PDF„ÇíÁîüÊàê„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÅ„Åó„Å∞„Çâ„Åè„ÅäÂæÖ„Å°„Åè„Å†„Åï„ÅÑ...",
        "pdf_done": "PDF„ÅåÁîüÊàê„Åï„Çå„Åæ„Åó„Åü",
        "pdf_name": "Ë™øÊüª„É¨„Éù„Éº„Éà"
    },
    "KR": {
        "title": "ÏÑ§Î¨∏ Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑùÍ∏∞",
        "subtitle": "Îç∞Ïù¥ÌÑ∞ ÏóÖÎ°úÎìú, ÌÉêÏÉâ, Î∂ÑÏÑù Î∞è PDF Î≥¥Í≥†ÏÑú ÏÉùÏÑ±",
        "upload": "CSV / XLS / XLSX ÏóÖÎ°úÎìú",
        "preview": "Îç∞Ïù¥ÌÑ∞ ÎØ∏Î¶¨Î≥¥Í∏∞(ÏµúÎåÄ 1000Ìñâ)",
        "summary": "Îç∞Ïù¥ÌÑ∞ÏÖã ÏöîÏïΩ",
        "rows": "Ìñâ",
        "cols": "Ïó¥",
        "num_cols": "Ïà´Ïûê Ïó¥",
        "cat_cols": "Î≤îÏ£º Ïó¥",
        "text_cols": "ÌÖçÏä§Ìä∏ Ïó¥",
        "descriptive_tab": "Í∏∞Ïà† ÌÜµÍ≥Ñ",
        "visual_tab": "ÏãúÍ∞ÅÌôî",
        "corr_tab": "ÏÉÅÍ¥Ä Î∞è Í≤ÄÏ†ï",
        "text_tab": "ÌÖçÏä§Ìä∏ Ï≤òÎ¶¨",
        "select_numeric": "Ïà´Ïûê Ïó¥ ÏÑ†ÌÉù",
        "stats_title": "Í∏∞Ïà† ÌÜµÍ≥ÑÎüâ",
        "normality_title": "Ï†ïÍ∑úÏÑ± Í≤ÄÏ†ï (D'Agostino & Pearson)",
        "statistic": "Í≤ÄÏ†ïÌÜµÍ≥ÑÎüâ",
        "p_value": "pÍ∞í",
        "interpretation": "Ìï¥ÏÑù",
        "histogram": "ÌûàÏä§ÌÜ†Í∑∏Îû®",
        "boxplot": "Î∞ïÏä§ÌîåÎ°Ø",
        "frequency_table": "ÎπàÎèÑÌëú(Í∞úÏàò + Î∞±Î∂ÑÏú®)",
        "select_x": "X ÏÑ†ÌÉù(Ïà´Ïûê)",
        "select_y": "Y ÏÑ†ÌÉù(Ïà´Ïûê)",
        "scatter_title": "ÏÇ∞Ï†êÎèÑ",
        "bar_chart": "ÎßâÎåÄ Ï∞®Ìä∏(ÏÉÅÏúÑ20)",
        "select_categorical": "Î≤îÏ£ºÌòï Ïó¥ ÏÑ†ÌÉù",
        "pearson": "ÌîºÏñ¥Ïä® ÏÉÅÍ¥Ä",
        "spearman": "Ïä§ÌîºÏñ¥Îßå ÏÉÅÍ¥Ä",
        "chi_square": "Ïπ¥Ïù¥Ï†úÍ≥± Í≤ÄÏ†ï",
        "observed": "Í¥ÄÏ∏°Í∞í",
        "expected": "Í∏∞ÎåÄÍ∞í",
        "corr_matrix": "ÌîºÏñ¥Ïä® ÏÉÅÍ¥Ä ÌñâÎ†¨",
        "spearman_matrix": "Ïä§ÌîºÏñ¥Îßå ÏÉÅÍ¥Ä ÌñâÎ†¨",
        "detect_text": "Í∞êÏßÄÎêú ÌÖçÏä§Ìä∏ Ïó¥",
        "preprocess": "ÌÖçÏä§Ìä∏ Ï†ÑÏ≤òÎ¶¨(ÏÜåÎ¨∏Ïûê, Íµ¨ÎëêÏ†ê Ï†úÍ±∞, ÌÜ†ÌÅ∞Ìôî, Î∂àÏö©Ïñ¥ Ï†úÍ±∞)",
        "sample_tokens": "ÌÜ†ÌÅ∞ ÏÉòÌîå",
        "top_words": "ÏÉÅÏúÑ10Í∞ú Îã®Ïñ¥",
        "generate_pdf": "PDF Î≥¥Í≥†ÏÑú ÏÉùÏÑ±",
        "download_pdf": "PDF Îã§Ïö¥Î°úÎìú",
        "dark_mode": "Îã§ÌÅ¨ Î™®Îìú",
        "language": "Ïñ∏Ïñ¥",
        "no_data": "Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏäµÎãàÎã§. ÌååÏùºÏùÑ ÏóÖÎ°úÎìúÌïòÏÑ∏Ïöî.",
        "insufficient": "Ïù¥ ÏûëÏóÖÏóê Îç∞Ïù¥ÌÑ∞Í∞Ä Ï∂©Î∂ÑÌïòÏßÄ ÏïäÏäµÎãàÎã§",
        "pdf_generating": "PDF ÏÉùÏÑ± Ï§ëÏûÖÎãàÎã§... Ïû†ÏãúÎßå Í∏∞Îã§Î†§ Ï£ºÏÑ∏Ïöî",
        "pdf_done": "PDF ÏÉùÏÑ± ÏôÑÎ£å",
        "pdf_name": "ÏÑ§Î¨∏_Î≥¥Í≥†ÏÑú"
    }
}

# --------------------------
# Helper: get_text with fallback
# --------------------------
def get_text(key: str) -> str:
    lang = st.session_state.get("language", "EN")
    if lang not in TEXTS:
        lang = "EN"
    return TEXTS.get(lang, TEXTS["EN"]).get(key, TEXTS["EN"].get(key, key))

# --------------------------
# Ensure NLTK stopwords available
# --------------------------
try:
    _ = stopwords.words("english")
except Exception:
    try:
        nltk.download("stopwords", quiet=True)
    except Exception:
        pass

# --------------------------
# Utility functions
# --------------------------
@st.cache_data
def load_data(uploaded_file) -> pd.DataFrame:
    if uploaded_file is None:
        return None
    name = uploaded_file.name.lower()
    try:
        if name.endswith(".csv"):
            return pd.read_csv(uploaded_file)
        else:
            return pd.read_excel(uploaded_file)
    except Exception:
        uploaded_file.seek(0)
        try:
            return pd.read_table(uploaded_file)
        except Exception as e:
            raise e

def safe_numeric_series(series: pd.Series) -> pd.Series:
    return pd.to_numeric(series, errors="coerce").dropna()

def descriptive_stats(series: pd.Series) -> dict:
    s = safe_numeric_series(series)
    if s.empty:
        return {}
    return {
        "count": int(s.count()),
        "mean": float(s.mean()),
        "median": float(s.median()),
        "mode": s.mode().tolist()[:3],
        "min": float(s.min()),
        "max": float(s.max()),
        "std": float(s.std()),
    }

def preprocess_text_series(series: pd.Series, remove_stopwords=True):
    if series is None:
        return [], Counter()
    try:
        sw = set(stopwords.words("english")) if remove_stopwords else set()
    except Exception:
        sw = set()
    translator = str.maketrans("", "", string.punctuation)
    cleaned = series.dropna().astype(str).str.lower().str.translate(translator)
    tokens = cleaned.apply(lambda x: [t for t in x.split() if t and (t not in sw)])
    cnt = Counter([w for sub in tokens for w in sub])
    return tokens, cnt

def fig_to_image_reader(fig, dpi=150):
    buf = BytesIO()
    fig.savefig(buf, format="PNG", bbox_inches="tight", dpi=dpi)
    plt.close(fig)
    buf.seek(0)
    return ImageReader(buf), buf

# --------------------------
# PDF builder (reportlab)
# --------------------------
def build_survey_report_pdf(df: pd.DataFrame, lang: str = "EN") -> bytes:
    buffer = BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=A4, rightMargin=30, leftMargin=30, topMargin=30, bottomMargin=18)
    styles = getSampleStyleSheet()
    flow = []

    # Header
    flow.append(Paragraph(get_text("title"), styles["Title"]))
    flow.append(Paragraph(get_text("subtitle"), styles["Normal"]))
    flow.append(Spacer(1, 8))
    flow.append(Paragraph(f"{get_text('rows')}: {len(df)}  |  {get_text('cols')}: {len(df.columns)}", styles["Normal"]))
    flow.append(Spacer(1, 12))

    num_df = df.select_dtypes(include=np.number)
    cat_df = df.select_dtypes(exclude=np.number)
    text_cols = [c for c in df.columns if df[c].dtype == object]

    # Numeric columns (limit to 6 to avoid huge PDF)
    for col in list(num_df.columns)[:6]:
        s = safe_numeric_series(df[col])
        flow.append(Paragraph(f"<b>{col}</b>", styles["Heading2"]))
        if s.empty:
            flow.append(Paragraph(get_text("insufficient"), styles["Normal"]))
            flow.append(Spacer(1, 6))
            continue
        desc = descriptive_stats(s)
        flow.append(Paragraph(f"Count: {desc['count']}, Mean: {desc['mean']:.4f}, Median: {desc['median']:.4f}, Std: {desc['std']:.4f}", styles["Normal"]))
        flow.append(Paragraph(f"Min: {desc['min']}, Max: {desc['max']}", styles["Normal"]))
        # Normality
        try:
            if len(s) >= 8:
                stat, p = normaltest(s)
                flow.append(Paragraph(f"{get_text('normality_title')}: stat={stat:.4f}, p={p:.6f}", styles["Normal"]))
            else:
                flow.append(Paragraph(f"{get_text('normality_title')}: need >=8 values", styles["Normal"]))
        except Exception:
            flow.append(Paragraph(f"{get_text('normality_title')}: error computing", styles["Normal"]))
        flow.append(Spacer(1, 6))
        # Plots
        try:
            fig1, ax1 = plt.subplots(figsize=(6, 2.2))
            sns.histplot(s, kde=True, ax=ax1)
            ax1.set_title(f"{col} - {get_text('histogram')}")
            img1, buf1 = fig_to_image_reader(fig1)
            flow.append(Image(img1, width=400, height=140))
            flow.append(Spacer(1, 6))
        except Exception:
            pass
        try:
            fig2, ax2 = plt.subplots(figsize=(6, 1.4))
            sns.boxplot(x=s, ax=ax2)
            ax2.set_title(f"{col} - {get_text('boxplot')}")
            img2, buf2 = fig_to_image_reader(fig2)
            flow.append(Image(img2, width=400, height=110))
            flow.append(Spacer(1, 12))
        except Exception:
            pass

    # Correlation matrix
    if num_df.shape[1] >= 2:
        flow.append(Paragraph(get_text("corr_matrix"), styles["Heading2"]))
        corr = num_df.corr().round(3)
        headers = [""] + list(corr.columns)
        table_data = [headers]
        for idx in corr.index:
            row = [idx] + [str(corr.loc[idx, c]) for c in corr.columns]
            table_data.append(row)
        flow.append(Table(table_data))
        flow.append(Spacer(1, 12))

        # Spearman correlation matrix
        flow.append(Paragraph(get_text("spearman_matrix"), styles["Heading2"]))
        spearman_corr = num_df.corr(method='spearman').round(3)
        headers_spearman = [""] + list(spearman_corr.columns)
        table_data_spearman = [headers_spearman]
        for idx in spearman_corr.index:
            row = [idx] + [str(spearman_corr.loc[idx, c]) for c in spearman_corr.columns]
            table_data_spearman.append(row)
        flow.append(Table(table_data_spearman))
        flow.append(Spacer(1, 12))

    # Categorical top 10
    if not cat_df.empty:
        flow.append(Paragraph("Categorical frequency (top 10)", styles["Heading2"]))
        for col in list(cat_df.columns)[:8]:
            flow.append(Paragraph(f"<b>{col}</b>", styles["Heading3"]))
            vc = df[col].fillna("(Missing)").astype(str).value_counts().head(10)
            table_data = [["Category", "Count", "Percent"]]
            for k, v in vc.items():
                pct = (v / len(df)) * 100
                table_data.append([str(k), str(int(v)), f"{pct:.1f}%"])
            flow.append(Table(table_data))
            flow.append(Spacer(1, 6))

    # Text top words
    if text_cols:
        flow.append(Paragraph(get_text("processing_text"), styles["Heading2"]))
        for col in text_cols[:6]:
            flow.append(Paragraph(f"<b>{col}</b>", styles["Heading3"]))
            try:
                _, counter = preprocess_text_series(df[col])
                table_data = [["Word", "Count"]]
                for w, cnt in counter.most_common(10):
                    table_data.append([w, str(cnt)])
                flow.append(Table(table_data))
                flow.append(Spacer(1, 6))
            except Exception:
                flow.append(Paragraph("Error processing text", styles["Normal"]))

    # Footer
    flow.append(Spacer(1, 10))
    flow.append(Paragraph(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", styles["Normal"]))

    # Build PDF
    try:
        doc.build(flow)
        buffer.seek(0)
        pdf_bytes = buffer.getvalue()
    finally:
        buffer.close()
    return pdf_bytes

# --------------------------
# Streamlit UI
# --------------------------
st.set_page_config(page_title="Survey Data Analyzer", layout="wide")
# orange background
st.markdown("""
    <style>
    .stApp { background-color: #FFA64D !important; }
    .block-container { padding: 1rem 2rem; }
    </style>
    """, unsafe_allow_html=True)

# init session state
if "language" not in st.session_state:
    st.session_state["language"] = "EN"
if "dark_mode" not in st.session_state:
    st.session_state["dark_mode"] = False
if "last_pdf" not in st.session_state:
    st.session_state["last_pdf"] = None

# top controls
col_a, col_b = st.columns([1, 2])
with col_a:
    st.session_state["dark_mode"] = st.checkbox(get_text("dark_mode"), value=st.session_state["dark_mode"])
with col_b:
    st.session_state["language"] = st.radio(get_text("language"), options=["EN", "ID", "CN", "JP", "KR"], index=["EN", "ID", "CN", "JP", "KR"].index(st.session_state["language"]), horizontal=True)

st.title(get_text("title"))
st.caption(get_text("subtitle"))

# file uploader
uploaded = st.file_uploader(get_text("upload"))
if uploaded is None:
    st.info(get_text("no_data"))
    st.stop()

# load data
try:
    df = load_data(uploaded)
except Exception as e:
    st.error(f"Error loading file: {e}")
    st.stop()

# preview & summary
st.subheader(get_text("preview"))
st.dataframe(df.head(1000))

num_df = df.select_dtypes(include=np.number)
cat_df = df.select_dtypes(exclude=np.number)
text_cols = [c for c in df.columns if df[c].dtype == object]

c1, c2, c3, c4, c5, c6 = st.columns(6)
c1.metric(get_text("rows"), df.shape[0])
c2.metric(get_text("cols"), df.shape[1])
c3.metric(get_text("num_cols"), num_df.shape[1])
c4.metric(get_text("cat_cols"), cat_df.shape[1])
c5.metric(get_text("x_total"), df.shape[0] * df.shape[1])
c6.metric(get_text("y_total"), df.isnull().sum().sum())
st.write(f"Interpretation: The dataset summary indicates {df.shape[0]} rows, {df.shape[1]} columns, {num_df.shape[1]} numeric columns, {cat_df.shape[1]} categorical columns, {get_text('x_total')} {df.shape[0] * df.shape[1]}, and {get_text('y_total')} {df.isnull().sum().sum()}. üìä")

# tabs
tabs = st.tabs([get_text("descriptive_tab"), get_text("visual_tab"), get_text("corr_tab"), get_text("text_tab")])

# Descriptive Stats tab
with tabs[0]:
    st.header(get_text("descriptive_tab"))
    if num_df.shape[1] == 0:
        st.info(get_text("insufficient"))
    else:
        sel_num = st.selectbox(get_text("select_numeric"), options=list(num_df.columns))
        if sel_num:
            s = safe_numeric_series(df[sel_num])
            if s.empty:
                st.write(get_text("insufficient"))
            else:
                stats = descriptive_stats(s)
                st.write(pd.DataFrame(stats, index=[sel_num]).T)
                st.write(f"Interpretation: Descriptive statistics for '{sel_num}' show the central tendency, spread, and distribution of the data. üìà")
                # normality
                if len(s) >= 8:
                    try:
                        stat, p = normaltest(s)
                        st.write(get_text("normality_title"))
                        st.write({get_text("statistic"): float(stat), get_text("p_value"): float(p)})
                        st.write(get_text("interpretation") + ": " + (get_text("normal") if p > 0.05 else get_text("not_normal")) + " üîç")
                    except Exception:
                        st.write("Normality test: error")
                else:
                    st.write(f"{get_text('normality_title')}: need at least 8 non-missing values")

                # plots
                fig, ax = plt.subplots()
                sns.histplot(s, kde=True, ax=ax)
                ax.set_title(f"{sel_num} - {get_text('histogram')}")
                st.pyplot(fig)
                plt.close(fig)

                fig2, ax2 = plt.subplots()
                sns.boxplot(x=s, ax=ax2)
                ax2.set_title(f"{sel_num} - {get_text('boxplot')}")
                st.pyplot(fig2)
                plt.close(fig2)

    # categorical frequency tables
    st.subheader(get_text("frequency_table"))
    if cat_df.shape[1] == 0:
        st.info(get_text("insufficient"))
    else:
        sel_cat = st.selectbox(get_text("select_categorical"), options=list(cat_df.columns), key="freq_cat")
        if sel_cat:
            vc = df[sel_cat].fillna("(Missing)").astype(str).value_counts()
            pct = (vc / vc.sum()) * 100
            out = pd.DataFrame({"count": vc, "percent": pct})
            # Add total row
            total_row = pd.Series({"count": vc.sum(), "percent": 100.0}, name="Total")
            out = pd.concat([out, pd.DataFrame([total_row])])
            st.dataframe(out.head(101))  # head(101) to include total
            # Interpretation
            most_freq = vc.idxmax()
            pct_most = pct.loc[most_freq]
            st.write(f"Interpretation: The most frequent category is '{most_freq}' with {pct_most:.1f}%. üèÜ")

# Visualizations tab
with tabs[1]:
    st.header(get_text("visual_tab"))
    # Histogram & Boxplot
    if num_df.shape[1] > 0:
        sel_hist = st.selectbox(get_text("histogram"), options=list(num_df.columns), key="vis_hist")
        s = safe_numeric_series(df[sel_hist])
        if s.empty:
            st.write(get_text("insufficient"))
        else:
            fig, ax = plt.subplots()
            sns.histplot(s, kde=True, ax=ax)
            ax.set_title(f"{sel_hist} - {get_text('histogram')}")
            st.pyplot(fig)
            plt.close(fig)
            st.write(f"Interpretation: The histogram displays the frequency distribution of '{sel_hist}', showing how values are spread across the range. üìä")

            fig2, ax2 = plt.subplots()
            sns.boxplot(x=s, ax=ax2)
            ax2.set_title(f"{sel_hist} - {get_text('boxplot')}")
            st.pyplot(fig2)
            plt.close(fig2)
            st.write(f"Interpretation: The boxplot shows the quartiles, median, and potential outliers for '{sel_hist}'. üì¶")
    else:
        st.info(get_text("insufficient"))

    # Scatter plot (synchronized)
    st.subheader(get_text("scatter_title"))
    if num_df.shape[1] >= 2:
        xcol = st.selectbox(get_text("select_x"), options=list(num_df.columns), key="scatter_x")
        ycol = st.selectbox(get_text("select_y"), options=list(num_df.columns), index=1 if len(num_df.columns) > 1 else 0, key="scatter_y")
        if xcol and ycol:
            clean = df[[xcol, ycol]].dropna()
            if clean.shape[0] < 2:
                st.write(get_text("insufficient"))
            else:
                fig, ax = plt.subplots()
                ax.scatter(clean[xcol], clean[ycol], alpha=0.7)
                ax.set_xlabel(xcol); ax.set_ylabel(ycol)
                ax.set_title(f"{xcol} vs {ycol}")
                st.pyplot(fig)
                plt.close(fig)
                st.write(f"Interpretation: The scatter plot shows the relationship between '{xcol}' and '{ycol}', indicating direction and strength of association. üìà")
    else:
        st.info(get_text("need_two_numeric_scatter"))

    # Bar chart for categorical
    st.subheader(get_text("bar_chart"))
    if cat_df.shape[1] > 0:
        sel_cat_bar = st.selectbox(get_text("select_categorical") + " (for bar chart)", options=list(cat_df.columns), key="bar_cat")
        vc = df[sel_cat_bar].fillna("(Missing)").astype(str).value_counts().head(20)
        fig, ax = plt.subplots(figsize=(8, max(3, 0.25 * len(vc))))
        sns.barplot(x=vc.values, y=vc.index, ax=ax)
        ax.set_xlabel("Count"); ax.set_ylabel(sel_cat_bar)
        st.pyplot(fig)
        plt.close(fig)
        st.write(f"Interpretation: The bar chart displays the top 20 categories for '{sel_cat_bar}', showing their frequencies. üìä")
    else:
        st.info("No categorical columns for bar chart")

# Correlations & Tests tab
with tabs[2]:
    st.header(get_text("corr_tab"))
    # Pearson & Spearman
    st.subheader(f"{get_text('pearson')} & {get_text('spearman')}")
    if num_df.shape[1] >= 2:
        a = st.selectbox(get_text("select_two_numeric"), options=list(num_df.columns), key="corr_a")
        b = st.selectbox(get_text("select_second_numeric"), options=list(num_df.columns), index=1 if len(num_df.columns) > 1 else 0, key="corr_b")
        if a and b:
            clean = df[[a, b]].dropna()
            if clean.shape[0] < 2:
                st.write(get_text("insufficient"))
            else:
                try:
                    r, p = pearsonr(clean[a], clean[b])
                    st.write(f"{get_text('pearson')}: r = {r:.4f}, p = {p:.6f}")
                    st.write(get_text("interpretation_pearson") + ":", get_text("positive") if r > 0 else get_text("negative") if r < 0 else get_text("no_relation"), f" (|r|={abs(r):.3f}) üìà")
                except Exception:
                    st.write(get_text("pearson_error"))
                try:
                    rho, p2 = spearmanr(clean[a], clean[b])
                    st.write(f"{get_text('spearman')}: rho = {rho:.4f}, p = {p2:.6f}")
                    st.write(get_text("interpretation_spearman") + ":", get_text("positive") if rho > 0 else get_text("negative") if rho < 0 else get_text("no_relation"), f" (|rho|={abs(rho):.3f}) üìà")
                except Exception:
                    st.write(get_text("spearman_error"))
    else:
        st.info("Need at least two numeric columns for correlations")

    # Chi-square
    st.subheader(get_text("chi_square"))
    if cat_df.shape[1] >= 2:
        ca = st.selectbox(get_text("select_two_categorical") + " 1", options=list(cat_df.columns), key="chi_a")
        cb = st.selectbox(get_text("select_second_categorical"), options=list(cat_df.columns), index=1 if len(cat_df.columns) > 1 else 0, key="chi_b")
        if ca and cb:
            ct = pd.crosstab(df[ca].fillna("(Missing)").astype(str), df[cb].fillna("(Missing)").astype(str))
            if ct.size == 0 or ct.values.sum() == 0 or ct.shape[0] < 2 or ct.shape[1] < 2:
                st.write(get_text("insufficient"))
            else:
                try:
                    chi2, pval, dof, expected = chi2_contingency(ct)
                    st.write(f"chi2 = {chi2:.4f}, p = {pval:.6f}, dof = {dof}")
                    st.write(get_text("observed"))
                    st.dataframe(ct)
                    st.write(get_text("expected"))
                    st.dataframe(pd.DataFrame(expected, index=ct.index, columns=ct.columns))
                    st.write(get_text("interpretation_chi") + ": " + (get_text("significant") if pval < 0.05 else get_text("not_significant")) + " üîó")
                except Exception as e:
                    st.write(f"Chi-square error: {e}")
    else:
        st.info("Need at least two categorical columns for chi-square")

    # Correlation matrix
    st.subheader(get_text("corr_matrix"))
    if num_df.shape[1] > 1:
        st.dataframe(num_df.corr().round(4))
        st.write("Interpretation: The Pearson correlation matrix shows pairwise linear correlations between numeric variables. üìä")
    else:
        st.info(get_text("insufficient"))

    # Spearman correlation matrix
    st.subheader(get_text("spearman_matrix"))
    if num_df.shape[1] > 1:
        st.dataframe(num_df.corr(method='spearman').round(4))
        st.write("Interpretation: The Spearman correlation matrix shows pairwise monotonic correlations between numeric variables. üìä")
    else:
        st.info(get_text("insufficient"))

# Text Processing tab
with tabs[3]:
    st.header(get_text("text_tab"))
    if not text_cols:
        st.info("No text columns found")
    else:
        sel_text = st.selectbox(get_text("select_text_column"), options=text_cols, key="text_select")
        remove_sw = st.checkbox("Remove English stopwords (NLTK)", value=True)
        tokens, counter = preprocess_text_series(df[sel_text], remove_stopwords=remove_sw)
        st.subheader(get_text("sample_tokens"))
        try:
            st.write(tokens.head(5).to_dict())
        except Exception:
            st.write(list(tokens)[:5])
        st.subheader(get_text("top_words"))
        st.table(pd.DataFrame(counter.most_common(10), columns=["word", "count"]))
        # Interpretation
        if counter:
            most_common_word, most_common_count = counter.most_common(1)[0]
            st.write(f"Interpretation: The most frequent word is '{most_common_word}' with {most_common_count} occurrences. üìù")

# Export / PDF (main page, tidy)
st.markdown("---")
st.header("Export / Report")
col_info, col_gen, col_down = st.columns([3, 1, 1])
with col_info:
    st.write("Generate a PDF report that includes dataset metadata, numeric statistics, normality results, plots (histogram & boxplot), correlation matrix, top categorical frequencies, and top words for text columns. Limited number of items included to keep PDF manageable.")
with col_gen:
    if st.button(get_text("generate_pdf")):
        with st.spinner(get_text("pdf_generating")):
            try:
                pdf_bytes = build_survey_report_pdf(df, lang=st.session_state.get("language", "EN"))
                st.session_state["last_pdf"] = pdf_bytes
                st.success(get_text("pdf_done"))
            except Exception as e:
                st.error(f"Error generating PDF: {e}")
                st.session_state["last_pdf"] = None
with col_down:
    if st.session_state.get("last_pdf"):
        fname = f"{get_text('pdf_name')}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
        st.download_button(get_text("download_pdf"), data=st.session_state["last_pdf"], file_name=fname, mime="application/pdf")

# End
